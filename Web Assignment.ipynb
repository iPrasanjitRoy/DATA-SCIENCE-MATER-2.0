{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad76b0-6beb-47bf-86b2-999dcd7c7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. \n",
    "Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "\n",
    "Web scraping is used to gather large amounts of data from various websites efficiently and quickly.\n",
    "\n",
    "\n",
    "Web scraping is employed in several areas for different purposes.\n",
    "E-Commerce: Web Scraping can be used to periodically extract data of products from various e-commerce websites like Amazon, eBay, Google Shopping etc. Product details like price, description, images, reviews, rating etc. can be easily extracted using a web scraping software.\n",
    "\n",
    "\n",
    "Data Analysis : You might want to collect and analyze data related to a specific category from multiple websites. \n",
    "The category might be real estate, automobiles, electronic gadgets, industrial equipment, business contacts, marketing etc.\n",
    "\n",
    "\n",
    "Academic Research: Data is an integral part of any research, be it academic, marketing or scientific. A Web Scraper will help you gather structured data from multiple sources in the Internet with ease.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1064b6c-b686-4a7c-b99e-37f716f213b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "\n",
    "\n",
    "Manual Copy-Pasting: This basic method involves manually copying and pasting data from web pages into a local file or spreadsheet. \n",
    "It is simple but time-consuming, suitable for scraping small amounts of data or when the website doesn't have complex structure or a large number of pages.\n",
    "\n",
    "\n",
    "HTML Parsing: Web scraping libraries like BeautifulSoup (Python) or JSoup (Java) provide HTML parsing capabilities. \n",
    "These libraries parse the HTML structure of web pages and allow you to extract desired data using selectors such as CSS selectors or XPath expressions. HTML parsing is flexible and powerful, enabling efficient extraction of data from complex websites.\n",
    "\n",
    "\n",
    "API-Based Scraping: Some websites provide APIs (Application Programming Interfaces) that allow developers to access and retrieve structured data directly. API-based scraping involves sending requests to these APIs and parsing the JSON or XML responses to extract the desired data. \n",
    "This method is often more reliable and efficient since APIs are designed for data exchange.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eae187-b11d-426a-85ab-8eadd454c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "Beautiful Soup is a popular Python library for web scraping and parsing HTML or XML documents. \n",
    "It provides a convenient way to extract data from web pages by navigating and manipulating the parsed document tree.\n",
    "\n",
    "Its Used For :- \n",
    "HTML/XML Parsing: Beautiful Soup parses HTML or XML content and builds a parse tree, which represents the structure of the document. \n",
    "It handles faulty markup and poorly formatted documents, making it resilient to common web scraping challenges.\n",
    "\n",
    "\n",
    "Data Extraction: Once you have identified the desired elements, Beautiful Soup provides methods to extract the data they contain. \n",
    "You can retrieve the element's text, attribute values, or the HTML/XML markup itself. It simplifies the process of extracting structured data from web pages.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2a6a32-b785-4d81-9f2c-d86276b83d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is a lightweight framework to build websites. \n",
    "Weâ€™ll use this to parse our collected data and display it as HTML in a new HTML file.\n",
    "Flask adds flexibility and extensibility to web scraping projects, allowing you to create web interfaces, develop APIs, handle asynchronous scraping, store data, and automate scraping tasks. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3fc03c-32d3-4894-a877-1a2b740be066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service\n",
    "\n",
    "AWS CodePipeline: AWS CodePipeline is a fully managed continuous integration and continuous delivery (CI/CD) service provided by Amazon Web Services (AWS).\n",
    "It helps in automating the release process of software applications, enabling you to build, test, and deploy your code changes in a reliable and efficient manner.\n",
    "AWS CodePipeline provides flexibility and integration with other AWS services, allowing you to create sophisticated CI/CD workflows that fit your application deployment requirements.\n",
    "\n",
    "\n",
    "\n",
    "AWS Elastic Beanstalk: AWS Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) offered by AWS. \n",
    "It simplifies the process of deploying and managing applications in the AWS cloud without worrying about infrastructure provisioning or configuration details.\n",
    "\n",
    "In summary, AWS CodePipeline facilitates the automation of the software release process, while AWS Elastic Beanstalk simplifies the deployment and management of applications on the AWS cloud.\n",
    "These services work together to provide a streamlined and automated approach to continuous integration, continuous delivery, and application deployment on AWS.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff355d8-3de1-4f61-b3ec-9a05bd2113ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
